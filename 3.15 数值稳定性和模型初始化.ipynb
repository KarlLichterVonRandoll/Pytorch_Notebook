{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7657a6",
   "metadata": {},
   "source": [
    "# 3.15 数值稳定性和模型初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5bb632",
   "metadata": {},
   "source": [
    "理解了正向传播与反向传播以后，我们来讨论一下深度学习模型的数值稳定性问题以及模型参数的初始化方法。深度模型有关数值稳定性的典型问题是衰减（vanishing）和爆炸（explosion）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3b0f8",
   "metadata": {},
   "source": [
    "## 3.15.1 衰减和爆炸\n",
    "当神经网络的层数较多时，模型的数值稳定性容易变差。假设一个层数为$L$的多层感知机的第$l$层$\\boldsymbol{H}^{(l)}$的权重参数为$\\boldsymbol{W}^{(l)}$，输出层$\\boldsymbol{H}^{(L)}$的权重参数为$\\boldsymbol{W}^{(L)}$。为了便于讨论，不考虑偏差参数，且设所有隐藏层的激活函数为恒等映射（identity mapping）$\\phi(x) = x$。给定输入$\\boldsymbol{X}$，多层感知机的第$l$层的输出$\\boldsymbol{H}^{(l)} = \\boldsymbol{X} \\boldsymbol{W}^{(1)} \\boldsymbol{W}^{(2)} \\ldots \\boldsymbol{W}^{(l)}$。此时，如果层数$l$较大，$\\boldsymbol{H}^{(l)}$的计算可能会出现衰减或爆炸。举个例子，假设输入和所有层的权重参数都是标量，如权重参数为0.2和5，多层感知机的第30层输出为输入$\\boldsymbol{X}$分别与$0.2^{30} \\approx 1 \\times 10^{-21}$（衰减）和$5^{30} \\approx 9 \\times 10^{20}$（爆炸）的乘积。类似地，当层数较多时，梯度的计算也更容易出现衰减或爆炸。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4fd9ca",
   "metadata": {},
   "source": [
    "## 3.15.2 随机初始化模型参数\n",
    "在神经网络中，通常需要随机初始化模型参数，下面解释一下这样做的原因：  \n",
    "\n",
    "回顾一下多层感知机模型，假设输出层只保留一个输出单元 $o_1$，且隐藏层使用相同的激活函数。如果将每个隐藏单元的参数都初始化为相等的值，那么正向传播时每个隐藏单元将根据相同的输入计算出相同的值，并传递至输出层。在反向传播中，每个隐藏单元的参数梯度至相等。因此，这些参数在使用基于梯度的优化算法迭代后值依然相等。之后的迭代也是如此。在这种情况下，无论隐藏单元有多少，隐藏层本质上只有1个隐藏单元在发挥作用。因此，正如在前面的实验中所做的那样，我们通常将神经网络的模型参数，特别是权重参数，进行随机初始化。\n",
    "\n",
    ">这里的隐藏单元针对的是同一层的隐藏单元，即同一层的隐藏单元只有一个会发挥作用，如果有多个隐藏层，还是存在多个发挥作用的隐藏单元。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00a7cc",
   "metadata": {},
   "source": [
    "### 3.15.2.1 pytorch的默认随机初始化\n",
    "随机初始化模型参数的方法有很多。线性回归中，我们使用 torch.nn.init.normal_() 使模型 net 的权重参数采用正态分布的随机初始化方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3e09b",
   "metadata": {},
   "source": [
    "### 3.15.2.2 Xavier随机初始化\n",
    "还有一种比较常用的随机初始化方法叫作Xavier随机初始化。 假设某全连接层的输入个数为$a$，输出个数为$b$，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布\n",
    "\n",
    "$$U\\left(-\\sqrt{\\frac{6}{a+b}},\\sqrt{\\frac{6}{a+b}}\\right)$$\n",
    "\n",
    "它的设计主要考虑到，模型参数初始化后，每层输出的方差不该受该层输入个数影响，且每层梯度的方差也不该受该层输出个数影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9250d",
   "metadata": {},
   "source": [
    "# 小结\n",
    "* 深度模型有关数值稳定性的典型问题是衰减和爆炸。当神经网络的层数较多时，模型的数值稳定性容易变差。\n",
    "* 我们通常需要随机初始化神经网络的模型参数，如权重参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f61547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
